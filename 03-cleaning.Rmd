# Data transformation

```{r, message=FALSE, warning=FALSE}
library(here)
library(readr)
library(tidyverse)
library(socviz)
```

Most of our small auxiliary datasets have been pre-processed by data providing authorities, hence, we focused on the pre-processing of the major datasets. Please go to our [github repo chapter](https://github.com/NeverGiveUpDXQ/2020-U.S.-Election-Visualizations/blob/main/03-cleaning.Rmd) to see code in detail.

## Election Result Data Transformation 
For the election results data, we cleaned up two raw data: 1976-2016 historical election result and 2020 election popular vote share and vote margin. 

First, to compare historical popular vote results for *republicans* on the state level, we cleaned this dataset in following steps:

- Select columns we needed. i.e. `year`, `state`, `party` and `candidatevotes`.
- Filter column `party`. i.e. only contains democrats and republicans.
- Add a new column `ratio`, we define *ratio = candidatevotes_xxx/(candidatevotes_democrat+candidatevotes_republican)*
- Filter column `party`. i.e. only leave republican.
- Check duplicates and fix typos

```{r}
history_data <- readr::read_csv(here::here("./data/raw/1976-2016-president.csv"))

# temporary data
temp <- history_data %>%
  filter(!writein) %>%
  select(year, state,party,candidatevotes) %>%
  filter(party %in% c('democrat','republican'))

# add a new column `ratio`
history_election <- temp%>%
  group_by(year,state)%>%
  dplyr::summarise(ratio = candidatevotes/sum(candidatevotes))%>%
  ungroup()

history_election$party = temp$party
history_election_wider <- history_election %>%
  pivot_wider(names_from = party , values_from = ratio)

# check our data
# history_election_wider %>%
#    group_by(year, state) %>%
#    summarise(n = n())%>%
#    filter(n != 1)
# after checking the number, we don't have any duplicate records 
```

We then filtered all outliers which involved 3 states:**Utah**, **District of Columbia** and **Minnesota**. After checking data, we know that Republicans have never won D.C. and popular vote shares have always relatively low. So, it is reasonable. However, the share value of *Minnesota* for Republicans is abnormal as it is equal to 1. It is impossible that all voters chose one party.


```{r}
# check for outliers
# boxplot(history_election$ratio)
# It's impossible if share = 1
# So, in this step, we filter those outlier `ratio`

history_election %>%
  filter(ratio %in% boxplot.stats(history_election$ratio)$out)%>%
  mutate(ratio = round(ratio,4))
```

Going back to the raw data, we noticed that in those years, party name for Dem. is *democratic-farmer-labor* rather than *democrat*. 
```{r}
history_data %>%
  filter(year %in% c(2000,2004,2012)) %>%
  filter(state == 'Minnesota')%>%
  select(year,party,candidatevotes)
```

```{r}
temp1 <- history_data %>%
  filter(!writein) %>%
  select(year, state,party,candidatevotes) %>%
  filter(party %in% c('democrat','republican','democratic-farmer-labor'))

# reset
temp1$party[temp1$party=='democratic-farmer-labor'] = 'democrat'

# add a new column `ratio`
history_election <- temp1%>%
  group_by(year,state)%>%
  dplyr::summarise(ratio = candidatevotes/sum(candidatevotes))%>%
  ungroup()

history_election$party = temp1$party

history_election_wider <- history_election %>%
  pivot_wider(names_from = party , values_from = ratio)%>%
  mutate(dem_this_margin = round(democrat-republican,3))%>%
  select(c(year,state,dem_this_margin))
```

```{r}
write.csv(history_election_wider, file = here::here("data", "clean", "1976-2016election.csv"),row.names=FALSE)
```

After cleaning, it contains 3 columns and 561 records.
```{r, echo=FALSE, results='asis'}
knitr::kable(data.frame(
                description = c('year','state','dem_this_margin'),
                category = c("Which election year?","State name","candidate votes for democrat(%) - candidate votes for republican(%)")
              ), 
             col.names = c('Column','Description'),
             row.names = F,font_size = 10)
```

Then, we used historical U.S. presidential election data provided in the `socviz` library, but since the data for 2016 was provisional, we updated the [2016 data](https://en.wikipedia.org/wiki/2016_United_States_presidential_election) and also added the 2020 election data for our analysis.

```{r}
# Update data
data(elections_historic)
elections_historic_new <- elections_historic 
elections_historic_new$ec_pct[elections_historic_new$year == 2016] <- 304/(304+227)
elections_historic_new$popular_pct[elections_historic_new$year == 2016] <- 0.461
elections_historic_new$popular_margin[elections_historic_new$year == 2016] <- -0.021

elections_historic_full <- elections_historic_new
# back up
elections_historic_new <- elections_historic_new %>%
  select(c(win_party,popular_pct,ec_pct,winner_label))

# add data for 2020  
data2020 <- data.frame(win_party = 'Dem.',popular_pct = 0.514,ec_pct = 306/(306+232), winner_label = 'Biden 2020')

elections_historic_new <- rbind(elections_historic_new,data2020)

write.csv(elections_historic_new, file = here::here("data", "clean", "elections_historic_new.csv"),row.names=FALSE)
```

Next, we cleaned up the U.S. State Level Popular Vote Results of 2020 Presidential Election in following steps:

- Select columns we need. i.e. `stateid`, `state`, `dem_this_margin`, `dem_votes`, `rep_votes`.
- Add a new column `class` to indicate if it is `States that flipped from 2016`, `Democrats won`, or `Republicans won`. We define a state as `States that flipped from 2016` if it is one of **Arizona**, **Wisconsin**, **Michigan**, **Pennsylvania**, **Georgia**. Otherwise, we compared their votes for Democrats and votes for Republicans to determine their class.

```{r, eval = FALSE, echo=FALSE}
president2020 <- read_csv('./data/raw/Popular vote backend_1216.csv') %>%
  filter(state %in% usmap::statepop$full)%>%
  # Make column `state` consistent & we don't consider Maine/Nebraska districts
  select(stateid,state,dem_this_margin,dem_votes,rep_votes) %>%
  # we classfiy 3 levels: Dem. won, Rep. won and flipped states
  mutate(class = ifelse(stateid %in% c('AZ', 'WI', 'MI', 'PA', 'GA'),'States that flipped from 2016',ifelse(dem_votes>rep_votes,'Democrats won','Republicans won')))

write.csv(president2020, "./data/clean/president2020.csv",row.names = FALSE)
```


## Contribution Data Transformation

For the contributions receipt dataset, we extracted only relevant columns as described in Data Sources Chapter. We changed the data types for several columns to factorize categorical variables like `committee_name` and to store `contribution_receipt_date` in a datetime format for later visualizations. We filtered the `contributor_state` column to only keep the 50 states of the US plus D.C. and eliminated noise from funds raised from foreign countries. Also, we unified different formats in the `contributor_suffix` column to eliminate the redundant factor levels. To better scale the contributions, we focused only on individual contributions, thus we applied the `entity_type == "IND"` to get rid of the contributions from committees, PACs, and organizations. 

To save file-reading time and to meet analysis and visualization needs, we made multiple aggregations on different dimensions. We derived a data frame *contribution_by_date* from aggregating the processed data by `contribution_receipt_date`, and the sum of `contribution_receipt_amount` was calculated for this aggregated view. Additionally, we extracted the contributors' job titles from the column `contributor_occupation`, cleaned the texts following steps including: 

- Excluded records of uninformational or ineffective strings. For example, we got rid of records equal to "INFORMATION REQUESTED", "-", "NA", "UNKNOWN", etc.
- Gathered column values to a single string separated by blank spaces. We saved some two-word job titles like "SELF EMPLOYED" and "REAL ESTATE" with underlines to avoid them being separated apart.
- Inserted spaces to divide words that were sticked together. For example, records like "WRITEREDITORTEACHER" were converted to "WRITER EDITOR TEACHER" with spaces in between.
- Split the string to a vector of single words.
- Removed unnecessary punctuations and numbers.
- Fixed detectable typos and abbreviations
- Removed uninformational words stored in the [stop words](https://www.rdocumentation.org/packages/tidytext/versions/0.2.6/topics/stop_words) dataset of package `tidytext`. For example, words like "the", "of", and "and" do not add any insight but will distort the frequency distribution. 
Finally, the counts for each unique word were calculated and saved in a separate .csv file.


```{r, echo=FALSE,eval=FALSE}
contributions1 <- readr::read_csv(here::here("./data/raw/contribution_bind.csv"))

# Extract columns
DataDescription<- readr::read_csv(here::here("./data/DatasetDescription.csv"))
columns <- as.vector(DataDescription[13:25,1])

contributions1<- contributions1 %>%
  select(columns[1:12])

# Change data types and factorize categorical variables
contributions1$committee_name <- as.factor(contributions1$committee_name)
contributions1$committee_name <- fct_recode(contributions1$committee_name,TRUMP = "DONALD J. TRUMP FOR PRESIDENT, INC.",BIDEN = "BIDEN FOR PRESIDENT")
contributions1$contribution_receipt_date <- as.Date(contributions1$contribution_receipt_date, format = "%m/%d/%y")

# Filter contributor_state
state<- c("AL","AK","AZ","AR","CA","CO","CT","DE","DC","FL","GA","HI","ID","IL","IN","IA","KS","KY","LA","ME","MD","MA","MI","MN","MS","MO","MT","NE","NV", "NH", "NJ", "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY")

contributions1 <- contributions1[contributions1$contributor_state %in% state,]

#filter individual contributions
contributions1<- contributions1[contributions1$entity_type == "IND",]

write.csv(contributions1, file = here::here("data", "clean", "contribution_processed.csv"),row.names=FALSE)
```

```{r,eval=FALSE,echo=FALSE}
#Aggregations
contribution_by_date <-contributions1[order(contributions1$contribution_receipt_date, decreasing= F),] %>% 
  select(committee_name,contribution_receipt_date,contribution_receipt_amount) %>%
  group_by(contribution_receipt_date,committee_name) %>%
    summarise(Total = sum(contribution_receipt_amount))

write.csv(contribution_by_date, file = here::here("data", "clean", "contribution_by_date.csv"),row.names=FALSE)
```

```{r, eval = FALSE, echo=FALSE}
# Define a function to extract occupations

GetOccupation <- function(name){
  # Filter data by Candidate
  if (name == 'BIDEN'){
    contributions1 <- contributions1[contributions1$committee_name == 'BIDEN',]
  } else if (name == 'TRUMP'){
    contributions1 <- contributions1[contributions1$committee_name == 'TRUMP',]
  }
  
  # Get rid of ineffective string records
  INEFFECTIVE <- c("INFORMATION REQUESTED","INFORMATION REQUESTED PER BEST EFFORTS","-","--","NA","UNKNOWN")
  contributions1 <- contributions1 %>%
      mutate(contributor_occupation=replace(contributor_occupation,
                    contributor_occupation %in% INEFFECTIVE, ''))
                    
  # Extract occupation
  occupation <- contributions1 %>% select(contributor_occupation)
  occupation <- drop_empty_row(occupation)
  
  # Keep some two-word occupations to avoid them from being separated apart
  occupation[occupation=="NOT EMPLOYED"] <-"NOT_EMPLOYED"
  occupation[occupation=="VICE PRESIDENT"] <-"VICE_PRESIDENT"
  occupation[occupation=="SELF EMPLOYED"] <-"SELF_EMPLOYED"
  occupation[occupation=="REAL ESTATE"] <-"REAL_ESTATE"
  
  # Count the frequency
  occupation %>% count(contributor_occupation, name = "freq") %>% arrange(desc(freq))
  
  # Gather column values to a single string separated by a blank space
  oc_str<- occupation %>% pull(contributor_occupation) %>% paste(collapse = " ")
  
  # Divide words by a blank space
  patterns <- c("ATTORNEY","CONSULTANT","WRITER","PROFESSOR","DIRECTOR",
                "PHYSICIAN","CEO","ACTOR","ENGINEER","SELF_EMPLOYED",
                "VP","VICE_PRESIDENT","REAL_ESTATE","TEACHER")
  replacements <- c(" ATTORNEY "," CONSULTANT "," WRITER "," PROFESSOR "," DIRECTOR ",
                    " PHYSICIAN "," CEO "," ACTOR "," ENGINEER "," SELF_EMPLOYED ",
                    " VICE_PRESIDENT "," VICE_PRESIDENT "," REAL_ESTATE "," TEACHER ")
  for(i in 1:length(patterns)){
       oc_str <- gsub(patterns[i], replacements[i],oc_str)
  }
  
  # Split the string
  oc_str_sp<- unlist(strsplit(oc_str, "\\s+"))
  # Remove punctuation marks
  oc_str_sp <- gsub("[[:punct:]]", "", oc_str_sp)
  # Remove all rows starting with a number
  oc_str_sp <- grep('^[A-Z]', oc_str_sp, value=TRUE)
  
  # Fix Typos for top counts occupations
  oc_str_sp[grep('ACCOUNT|ACCNTNT|ACCOU|ACCT|ACOUNT', oc_str_sp)] <- "ACCOUNTANT"
  oc_str_sp[grep('ADMIN|ADMIST|ADMIIN|ADMN', oc_str_sp)] <- "ADMINISTRATOR"
  oc_str_sp[grep('RETIRED', oc_str_sp)] <- "RETIRED"
  oc_str_sp[grep('CONSULTING', oc_str_sp)] <- "CONSULTANT"
  oc_str_sp[grep('TECHNIC', oc_str_sp)] <- "TECHNICIAN"
  oc_str_sp[grep('WRIT', oc_str_sp)] <- "WRITER"
  oc_str_sp[grep('VETERNARIAN|VETERINARY', oc_str_sp)] <- "VETERINARIAN"
  oc_str_sp[grep('THERAP', oc_str_sp)] <- "THERAPIST"
  oc_str_sp[grep('TECHNOLOG|TECHS', oc_str_sp)] <- "TECH"
  oc_str_sp[grep('TEACH', oc_str_sp)] <- "TEACHER"
  oc_str_sp[grep('SEFTEMPLOYED|SELFEMPLOYE|SELEMPLOYED', oc_str_sp)] <- "SELFEMPLOYED"
  oc_str_sp[grep('ENGIINEERN|ENGIN|ENGNEER|ENIGEER|ENGENEER|ENGI|ENGNINEER|ENGONEER|ENIGNEER|ENINGEER', oc_str_sp)] <- "ENGINEER"
  oc_str_sp[grep('ENTREP|ENTERPRENEUR|ENTRREPRENEUR|ENTEREPRENEUR|ENTRPRENEUR', oc_str_sp)] <- "ENTREPRENEUR"
  oc_str_sp[grep('ATTO|ATTR|ATTIORNEY|ATTAORNEY|ATTIRNEY|ATTPRNEY|ATTTORNEY', oc_str_sp)] <- "ATTORNEY"
  oc_str_sp[grep('PHYSICI|PHYSCIAN|PHYISICIAN|PHYCISIAN|PHYSITION|PHYSCIAN|PHYSICAIN|PHYISICIAN|PHYSIAN|PHYSISIAN|PHYSICAN|PHYSISCIAN|PHYI|PHYSYCIAN|PHYSSICIAN|PHYSIVIAN|PHYSIACIAN', oc_str_sp)] <- "PHYSICIAN"
  oc_str_sp[grep('PROFESSO|PROFOESSOR|PROFESSPR|PROFESSIR|PROFFESE|PROFESSE|PROFESSSOR|PROFSSOR|PROFESOR|PROFESSR', oc_str_sp)] <- "PROFESSOR"
  
  #Build a data frame
  oc_df <- as.data.frame(oc_str_sp)
  
  # Remove all unnecessary words stored in the stop_words dataset
  data(stop_words)
  oc_df <- oc_df %>% 
    anti_join(stop_words %>% mutate(word=toupper(word)), by = c("oc_str_sp" = "word"))

  # Get the frequency table and pick top 50 words
  oc_df$oc_str_sp <- as.factor(oc_df$oc_str_sp)
  oc_count <- oc_df %>% count(oc_str_sp, name = "freq") %>% 
    filter(freq > 1) %>% 
    arrange(desc(freq)) %>% 
    head(50)
  
  # Replace underlines with blank spaces
  oc_count$oc_str_sp <- oc_count$oc_str_sp %>% 
      str_replace("NOTEMPLOYED","NOT EMPLOYED") %>% 
      str_replace("SELFEMPLOYED","SELF EMPLOYED") %>% 
      str_replace("VICEPRESIDENT","VICE PRESIDENT") %>%
      str_replace("REALESTATE","REAL ESTATE")
  
  # Save as a csv. file locally
  write.csv(oc_count, file=glue::glue("~/R/occupation_{name}_count.csv"),row.names = FALSE)
  
  return(oc_count)
}

# Get contributor occupations
oc_biden_count <- GetOccupation("BIDEN")
oc_trump_count <- GetOccupation("TRUMP")
```


## Disbursement Data Transformation
We first extracted the necessary columns that are mentioned in the previous chapter. Then we noticed that in the `disbursement_purpose_category`, there is a `OTHER` top coding dominates the dataset, hence it would not provide us lots of interesting information to analyze. Below is the original data distribution for the `disbursement_purpose_category` column:
```{r}
# Import data from csv
exp_raw <- readr::read_csv(here::here("./data/raw/schedule_b-2020-11-18T20_02_30.csv"))

# Extract specific columns
exp_processed <- exp_raw %>% 
  select(committee_name, disbursement_description, disbursement_date, disbursement_amount,
         disbursement_purpose_category, recipient_city, recipient_zip, recipient_state, recipient_name)

# Convert to correct data type and factor the data if necessary
exp_processed$disbursement_purpose_category <- factor(exp_processed$disbursement_purpose_category)

# Visualize some important data columns
ggplot(exp_processed) + 
  geom_bar(aes(y=fct_relevel(fct_infreq(disbursement_purpose_category) %>% fct_rev(), "OTHER"))) + 
  xlab("Count") +
    ylab("Disbursement Purpose") + 
  ggtitle("Distribution of disbursement_purpose_category") +
  theme_bw() +
  theme(plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "bold", color = "grey35"),
        plot.caption = element_text(color = "grey68"),
        legend.position="bottom")
```

But since we have another column which is the `disbursement_description`, we used this information to decode this top code. We examined the frequently mentioned terms in `disbursement_description` among those marked as `OTHER` and manually categorize them into existing or new categories that would fit the record type better. Below is a conversion table that we used to convert the columns. The pattern we are looking for in the description ar based on high frequent terms as well as their word stems and abbreviations. The conversion are done based on the order of this list. 
```{r, echo=FALSE, results='asis'}
knitr::kable(data.frame(
                description = c("BANK|PROCESS","CONSULT",
                                "SLRY|SALARY|OFFICE|PAYROLL|PYROLL|PHONE|RENT|SOFTWARE|COMPUTER",
                                "MARKET|MARKETING|ADVERTISING","TRAVEL|TRANSPORT","STAG|STAGING|SHIP",
                                "EVENT|CATER|UTIL", "CONTRIBUTION", "REFUND|MILEAGE|REIMBURSE"),
                category = c("BANKING", "CONSULTING", "ADMINISTRATIVE", "ADVERTISING",
                             "TRAVEL", "MATERIALS", "EVENTS", "CONTRIBUTIONS", "REFUNDS")
              ), 
             col.names = c('Category Description','New Category'),
             caption = "Disbursement Description to Category Conversion Table",
             row.names = F,font_size = 10)
```

```{r}
# label rows that will be changed before undo top coding 
exp_processed <- 
  transform(exp_processed, from_other=ifelse(disbursement_purpose_category=='OTHER', TRUE, FALSE))

# Add more factor levels to describe the purpose better
levels(exp_processed$disbursement_purpose_category) <-
  c(levels(exp_processed$disbursement_purpose_category), "BANKING", "CONSULTING")

# Decode disbursement_purpose_category based on the description
exp_processed[grepl("BANK|PROCESS",exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "BANKING"

exp_processed[grepl("CONSULT",exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "CONSULTING"

exp_processed[grepl("SLRY|SALARY|OFFICE|PAYROLL|PYROLL|PHONE|RENT|SOFTWARE|COMPUTER",
        exp_processed$disbursement_description, ignore.case=T) &
    exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "ADMINISTRATIVE"

exp_processed[grepl("MARKET|MARKETING|ADVERTISING", exp_processed$disbursement_description, ignore.case=T) &
    exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "ADVERTISING"

exp_processed[grepl("TRAVEL|TRANSPORT", exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "TRAVEL"

exp_processed[grepl("STAG|STAGING|SHIP", exp_processed$disbursement_description, ignore.case=T) & 
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "MATERIALS"

exp_processed[grepl("EVENT|CATER|UTIL",exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <- "EVENTS"

exp_processed[grepl("CONTRIBUTION", exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <-"CONTRIBUTIONS"

exp_processed[grepl("REFUND|MILEAGE|REIMBURSE", exp_processed$disbursement_description, ignore.case=T) &
  exp_processed$disbursement_purpose_category == "OTHER", ]$disbursement_purpose_category <-"REFUNDS"
```

Here is the distribution after undo the top coding:
```{r}
ggplot(exp_processed) + 
  geom_bar(aes(y=fct_relevel(fct_infreq(disbursement_purpose_category) %>% fct_rev(), "OTHER"))) + 
  labs(x="Count", y="Disbursement Purpose",
       title="Distribution of disbursement_purpose_category") +
  theme_bw() +
  theme(plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "bold", color = "grey35"),
        plot.caption = element_text(color = "grey68"),
        legend.position="bottom")
```

Now, the top coding category is less significant than before. We perform our further analysis based on this cleaned data set.
```{r}
write.csv(exp_processed, file = here::here("data", "clean", "disbursement_processed.csv"),row.names=FALSE)
```


